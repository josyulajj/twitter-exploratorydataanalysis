{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all packages and set plots to be embedded inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json as json\n",
    "import tweepy\n",
    "from timeit import default_timer as timer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up Plot style\n",
    "plt.style.use({'figure.facecolor':'white'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dataset\n",
    "tweet_df = pd.read_csv('twitter-archive-enhanced-2.csv')\n",
    "image_df = pd.read_csv('image-predictions-3.tsv', sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We make a copy of the loaded dataframe as a best practice.\n",
    "tweet_av_df = tweet_df.copy()\n",
    "image_pred_df = image_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual Assessment on Twitter archive content which contains basic tweet data ###\n",
    "-----\n",
    "For this project, key data assessment requirements for twitter archive data include original rating and there should be an image associated with the given rating.\n",
    "- \"expanded_urls\" is associated with image urls for a given tweet.\n",
    "- It is observed that the \"expanded_urls\" column does have missing or no values\n",
    "- \"rating_numerator\" gives us insights into the given dog rating.\n",
    "- \"tweet_id\" it a unique identifier identifying each unique tweet for each dog.\n",
    "- \"timestamp\" captures the date and time specifics when a direct message was posted to weratedogs\n",
    "- 2356 records in twitter archive data set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_av_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Programmatic Assessment on Twitter archive content which contains basic tweet data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tweet_av_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_av_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_av_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tweet_av_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_av_df.rating_numerator.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_av_df[['doggo', 'floofer', 'pupper', 'puppo']].apply(pd.Series.value_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Define - Data Quality Issues** ###\n",
    "----------\n",
    "- Completeness: The following columns are incomplete - and have missing values. \n",
    "'in_reply_to_status_id', 'in_reply_to_user_id', 'retweeted_status_id','retweeted_status_user_id', 'retweeted_status_timestamp','expanded_urls'.\n",
    "\n",
    "- Consistency: 'in_reply_to_user_id', 'retweeted_status_user_id' (status ids are sometimes populated with user_id).\n",
    "\n",
    "- Validity: 'rating_denominator' has 0 values in it. This will result in 0 rating for dogs.\n",
    "\n",
    "- Erroneous data types: 'timestamp', 'retweeted_status_timestamp' has been set as object type.\n",
    "\n",
    "- Erroneous data types: 'in_reply_to_status_id', 'in_reply_to_user_id', 'retweeted_status_id','retweeted_status_user_id' should be int type.\n",
    "\n",
    "- Accuracy: 'name' column has inaccurate values.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Code - Code to fix the data quality issues.** ###\n",
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing the 'timestamp' data quality issue. Converting object type to datetime64 with UTC timezone \n",
    "tweet_av_df['timestamp'] = pd.to_datetime(tweet_av_df['timestamp'], utc=True, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fixing 'expanded_urls' data quality issue. Delete rows that have null values since we only want original tweet ratings that have images.\n",
    "tweet_av_df = tweet_av_df.dropna(axis=0, subset=['expanded_urls'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fixing 'retweeted_status_id' data quality issue. We delete rows that have a value associated with retweeted_status_id since we only want original tweet ratings.\n",
    "tweet_av_df = tweet_av_df.drop(tweet_av_df.loc[tweet_av_df.retweeted_status_id.notna()].index)\n",
    "tweet_av_df.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Continue with 'retweeted_status_id' - since we are intrested with original tweets only, it is safe to drop this column since we are left with null values in this column.\n",
    "tweet_av_df.drop(axis=1, columns=['retweeted_status_id'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'retweeted_status_user_id' column can also be dropped since we are also left with null values. Keeping the original question in mind.\n",
    "tweet_av_df.drop(axis=1, columns=['retweeted_status_user_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'retweeted_status_timestamp' column can also be dropped since we are also left with null values. Keeping the original question in mind.\n",
    "tweet_av_df.drop(axis=1, columns=['retweeted_status_timestamp'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'in_reply_to_status_id' column can be dropped, since we are not really looking at tweets that were in reply.\n",
    "tweet_av_df.drop(axis=1, columns=['in_reply_to_status_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'in_reply_to_user_id' column can be dropped too, since we are not really looking at tweets that were in reply.\n",
    "tweet_av_df.drop(axis=1, columns=['in_reply_to_user_id'], inplace=True)"
   ]
  },
  {
   "source": [
    "### **Test** ###\n",
    "------"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Taking a peek at tweet dataframe after fixing the data quality issues.\n",
    "tweet_av_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Assessment Findings on Image Predictions data set ###\n",
    "------\n",
    "**Data Quality Issues**\n",
    "\n",
    "- No data quality issues were found with this data set. The dataset is complete, consistent, valid with no accuracy issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather Favourite and Retweet Count using Twitter api ###\n",
    "-----\n",
    "\n",
    "Before we proceed with data tidy tasks., we will gather favourite and retweet count data using twitter api."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# A function to collect tweet json data using twitter api and save it to json file.\n",
    "def collecttweetdata(tweet_ids):\n",
    "    consumer_key = ''\n",
    "    consumer_secret = ''\n",
    "    \n",
    "    auth = tweepy.AppAuthHandler(consumer_key, consumer_secret)\n",
    "    api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "    count = 0\n",
    "    fails_dict = {}\n",
    "    start = timer()\n",
    "    with open('tweet-json.txt', 'w') as outfile:\n",
    "        for tweet_id in tweet_ids:\n",
    "            count += 1\n",
    "            print(str(count) + \": \" + str(tweet_id))\n",
    "            try:\n",
    "                tweetjson = api.get_status(tweet_id, tweet_mode=\"extended\")\n",
    "                print(\"Success\")\n",
    "                json.dump(tweetjson._json, outfile)\n",
    "                outfile.write('\\n')\n",
    "            except tweepy.TweepError as e:\n",
    "                print(\"Fail\", e)\n",
    "                fails_dict[tweet_id] = e\n",
    "                pass\n",
    "    end = timer()\n",
    "    print(end - start)\n",
    "    print(fails_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lets collect tweet data and save to tweets data json file.\n",
    "tweet_ids = tweet_av_df.tweet_id.values\n",
    "collecttweetdata(tweet_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating dataframe from the tweet json that will have the 'favorite_count' and 'retweet_count'\n",
    "def is_json_key_present(json, key):\n",
    "    try:\n",
    "        buf = json[key]\n",
    "    except KeyError:\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "column_names = [\"tweet_id\", \"favorite_count\", \"retweet_count\"]\n",
    "list_vals = []\n",
    "with open('tweet-json.txt','r') as jfile:\n",
    "    for line in jfile:\n",
    "        try:\n",
    "            myjson = json.loads(line)\n",
    "            if (is_json_key_present(myjson,'id') and  is_json_key_present(myjson,'favorite_count') and is_json_key_present(myjson,'retweet_count')):\n",
    "                vals = [myjson['id'], myjson['favorite_count'], myjson['retweet_count']]\n",
    "                list_vals.append(vals)\n",
    "            else:\n",
    "                print('Skipping row as there is no data')\n",
    "        except:\n",
    "            pass\n",
    "tweet_data_df = pd.DataFrame(list_vals, columns=column_names)\n",
    "print(tweet_data_df.shape, tweet_data_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### **Define - Tideness issues - 1** ###\n",
    "----------\n",
    "\n",
    "The following tidiness issues were identified.\n",
    "\n",
    "- The retweet and favorite count belong to twitter data set - to form an observational unit (table).\n",
    "- As each variable forms a column, the columns on twitter data set 'doggo', 'floofer', 'pupper', 'puppo' are identifying various stages of dog. We fix this by creating a single column 'growth_stage' that captures the dog stage.\n",
    "- The image predictions data can also be combined with twitter data set to form an observational unit from where the predictions on each tweet can be analyzed.\n"
   ]
  },
  {
   "source": [
    "### **Code - Code to fixe the data quality issues.** ###\n",
    "--------"
   ],
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge tweet archive data set with tweet json data set that has favorite and retweet count.\n",
    "twitter_av_favs_df =  tweet_av_df.merge(tweet_data_df, on='tweet_id')"
   ]
  },
  {
   "source": [
    "### **Test - the data quality issues.** ###\n",
    "--------"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "twitter_av_favs_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### **Define - Tideness issues - 2** ###\n",
    "----------\n",
    "\n",
    "The columns on twitter archive data set 'doggo', 'floofer', 'pupper', 'puppo' are identifying various stages of dog. We fix this wide form of data by creating a single column 'growth_stage' that captures the dog stage.\n",
    "\n",
    "I created a function to melt the individual stage columns into a single column to identify the existing stage of the dog. The highest stage takes precedence when a tweet indicates multiple stages of the dog.\n"
   ]
  },
  {
   "source": [
    "### **Code - Code to fix the data quality issues.** ###\n",
    "--------"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Custom function to derive the current stage of the dog and create a dataframe to hold the tweet_id and the growth_stage.\n",
    "def dog_stages(twitter_avfavsdf):\n",
    "    stages_dict = {}\n",
    "    for i in range(len(twitter_avfavsdf)):\n",
    "        row = twitter_avfavsdf.iloc[i]\n",
    "        stage = \"unknown\"\n",
    "        if (row.floofer == \"floofer\"):\n",
    "            stage = \"floofer\"\n",
    "        elif (row.puppo == \"puppo\"):\n",
    "            stage = \"puppo\"\n",
    "        elif (row.pupper == \"pupper\"):\n",
    "            stage = \"pupper\"\n",
    "        elif (row.doggo == \"doggo\"):\n",
    "            stage = \"doggo\"\n",
    "        stages_dict[row.tweet_id] = stage\n",
    "    return stages_dict\n",
    "\n",
    "stage_dictn = dog_stages(twitter_av_favs_df)\n",
    "stage_df = pd.DataFrame(stage_dictn.items(), columns=['tweet_id', 'growth_stage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enriching the twitter data set that has favourite and retweet count with growth_stage column and creating a new data set.\n",
    "twitter_av_favsstages_df =  twitter_av_favs_df.merge(stage_df, on='tweet_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are going to drop the stage columns.\n",
    "twitter_av_favsstages_df.drop(axis=1, columns=['doggo', 'floofer', 'pupper', 'puppo'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally we will save this to our master data frame - 'twitter_archive_master.csv'.\n",
    "twitter_av_favsstages_df.to_csv('twitter_archive_master.csv', index=False)"
   ]
  },
  {
   "source": [
    "### **Test - the data quality issues.** ###\n",
    "--------"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lets get the shape and columns\n",
    "print(twitter_av_favsstages_df.shape, twitter_av_favsstages_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting a sample of our dataset\n",
    "twitter_av_favsstages_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizations to help us get insignts on WeRateDogs Twitter data ###\n",
    "\n",
    "- What was the most favorite dog stage on average?\n",
    "\n",
    "- What was the most retweeted dog stage on average?\n",
    "\n",
    "- Which dog stage are highly rated on average?\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_av_master_df = pd.read_csv('twitter_archive_master.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On twitter which dog stage has more faviourites on average?\n",
    "plt.figure(figsize=[16, 12])\n",
    "base_color = sb.color_palette()[0]\n",
    "splot = sb.barplot(x=\"growth_stage\", y=\"favorite_count\", data=twitter_av_master_df, ci=None, order=['doggo', 'pupper', 'puppo', 'floofer'], color=base_color)\n",
    "for p in splot.patches:\n",
    "    splot.annotate(format(p.get_height(), '.0f'), (p.get_x() + p.get_width() / 2., p.get_height()), ha = 'center', va = 'center', xytext = (0, 10), textcoords = 'offset points')\n",
    "plt.xlabel(\"Dog Stages\")\n",
    "plt.ylabel(\"Favorite Count\")\n",
    "plt.title(\"Favorite's by Dog Stages on Twitter\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On twitter which dog stage has high retweets on average?\n",
    "plt.figure(figsize=[16, 12])\n",
    "base_color = sb.color_palette()[0]\n",
    "splot = sb.barplot(x=\"growth_stage\", y=\"retweet_count\", data=twitter_av_master_df, ci=None, order=['doggo', 'pupper', 'puppo', 'floofer'], color=base_color)\n",
    "for p in splot.patches:\n",
    "    splot.annotate(format(p.get_height(), '.0f'), (p.get_x() + p.get_width() / 2., p.get_height()), ha = 'center', va = 'center', xytext = (0, 10), textcoords = 'offset points')\n",
    "plt.xlabel(\"Dog Stages\")\n",
    "plt.ylabel(\"Retweet Count\")\n",
    "plt.title(\"Retweet's by Dog Stages on Twitter\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How are the dogs rated by their stages?\n",
    "plt.figure(figsize=[16, 12])\n",
    "base_color = sb.color_palette()[0]\n",
    "\n",
    "splot = sb.barplot(x=\"growth_stage\", y=\"rating_numerator\", data=twitter_av_master_df, ci=None, order=['doggo', 'pupper', 'puppo', 'floofer'], color=base_color)\n",
    "for p in splot.patches:\n",
    "    splot.annotate(format(p.get_height(), '.0f'), (p.get_x() + p.get_width() / 2., p.get_height()), ha = 'center', va = 'center', xytext = (0, 10), textcoords = 'offset points')\n",
    "\n",
    "plt.xlabel(\"Dog Stages\")\n",
    "plt.ylabel(\"Rating on scale of 10\")\n",
    "plt.title(\"Rating averages by Dog Stages on Twitter\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insights from WeRateDogs data set ###\n",
    "\n",
    "- puppo dog stage was highly favorited on average by 21,631.\n",
    "\n",
    "- Again puppo dog stage was highly retweeted on average by 6292.\n",
    "\n",
    "- All three dog stages doggo, puppo, floofer were equally rated on average at 12. While pupper was only off by 1 rating.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}